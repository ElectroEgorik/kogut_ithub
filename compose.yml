version: '3.8'

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    networks:
      - hadoop_net
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      - ./local:/mnt
    environment:
      CLUSTER_NAME: test
      CORE_CONF_fs_defaultFS: "hdfs://namenode:9000"
      HDFS_CONF_dfs_replication: 1
      HDFS_CONF_dfs_client_use_datanode_hostname: "true"

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    networks:
      - hadoop_net
    ports:
      - 9866:9866
      - 9864:9864
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
      CORE_CONF_fs_defaultFS: "hdfs://namenode:9000"

  hive-server:
    image: apache/hive:4.1.0
    container_name: hive-server
    networks:
      - hadoop_net
    ports:
      - 10000:10000
      - 10002:10002
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 metastore:9083"
      HIVE_METASTORE_URI: thrift://metastore:9083
      CORE_CONF_fs_defaultFS: hdfs://namenode:9000
      SERVICE_NAME: hiveserver2
    volumes:
      - ./conf/core-site.xml:/opt/hive/conf/core-site.xml
    depends_on:
      - namenode
      - datanode
      
  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter
    networks:
      - hadoop_net
    ports:
      - 8888:8888
    user: root
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop
      - JUPYTER_TOKEN=mytoken123
    volumes:
      - ./notebooks:/home/jovyan
    depends_on:
      - namenode
      - datanode
      - hive-server

volumes:
  hadoop_namenode:
  hadoop_datanode:
  hive_postgres_data:

networks:
  hadoop_net:
    driver: bridge
